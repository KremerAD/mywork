{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "import csv\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_d = pd.read_csv('positive.csv',sep=';',header=None)\n",
    "p_d = p_d[[3,4]]\n",
    "p_d.columns = ['text','label']\n",
    "n_d = pd.read_csv('negative.csv',sep=';',header=None)\n",
    "n_d = n_d[[3,4]]\n",
    "n_d.columns = ['text','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "mystem = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner_pymorphy(text):\n",
    "    text = text.lower()\n",
    "    alph = 'абвгдеёжзийклмнопрстуфчцчшщъыьэюя'\n",
    "    cleaned_text = ''\n",
    "    for char in text:\n",
    "        if(char.isalpha() and char[0] in alph) or (char == ' '):\n",
    "            cleaned_text += char\n",
    "    result = []\n",
    "    for word in cleaned_text.split():\n",
    "        result.append(morph.parse(word)[0].normal_form)\n",
    "    return ' '.join(result)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_d['text'] = p_d['text'].apply(text_cleaner_pymorphy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_d['text'] = n_d['text'].apply(text_cleaner_pymorphy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_d.to_csv('cleaned_positiv.csv',index=False)\n",
    "n_d.to_csv('cleaned_negative.csv',index=False)\n",
    "p_count = len(p_d.index)/2\n",
    "n_count = len(n_d.index)/2\n",
    "p_d_teach = p_d['text'][:int(p_count)]\n",
    "n_d_teach = n_d['text'][:int(n_count)]\n",
    "\n",
    "#p_d_teach = p_d['text'][:10000]\n",
    "#n_d_teach = n_d['text'][:10000]\n",
    "\n",
    "p_d_teach.to_csv('cleaned_positiv_text.csv',index = False, header = False)\n",
    "n_d_teach.to_csv('cleaned_negative_text.csv',index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probabilities(file,h):\n",
    "    import csv\n",
    "    import codecs\n",
    "    import pymorphy2.tokenizers\n",
    "    \n",
    "    Read_file = csv.DictReader(codecs.open(file,\"r\",\"utf-8\"),delimiter = ';')\n",
    "    words = []\n",
    "    for row in Read_file:\n",
    "        words += pymorphy2.tokenizers.simple_word_tokenize(str(row))\n",
    "    \n",
    "    unique_words = set(words)\n",
    "    \n",
    "    p = dict.fromkeys(unique_words, 0)\n",
    "    for item in words:\n",
    "        p[item]+=1./len(words)\n",
    "    \n",
    "    if h == 0:\n",
    "        Write_file = open(\"prob1.csv\", \"w\")\n",
    "    if h == 1:\n",
    "        Write_file = open(\"prob2.csv\", \"w\")\n",
    "    \n",
    "    Write_file.write(\"word;probability\\n\")\n",
    "    \n",
    "    for key2,value2 in p.items():\n",
    "        result = str(key2) + \";\" + str(value2) +\"\\n\"\n",
    "        Write_file.write(result) \n",
    "        \n",
    "    return (p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors(f_set,f_dict):\n",
    "    for value,key in f_dict.items():\n",
    "        flag=0;\n",
    "        for item in f_set:\n",
    "            if(item==value):\n",
    "                flag=1\n",
    "        if flag==0:\n",
    "            del f_dict[value]\n",
    "        return(f_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob1 = get_probabilities(\"cleaned_positiv_text.csv\",0)\n",
    "prob2 = get_probabilities(\"cleaned_negative_text.csv\",1)\n",
    "\n",
    "general = set(dict.keys(prob1)) & set(dict.keys(prob2))\n",
    "\n",
    "prob1 = errors(general,prob1)\n",
    "prob2 = errors(general,prob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "Write_file = codecs.open(\"dictionary.csv\", \"w\", \"utf-8\")\n",
    "Write_file.write(\"word;weirdness\\n\")\n",
    "for key1, value1 in prob1.items():\n",
    "    for key2, value2 in prob2.items():\n",
    "        if(key1==key2):\n",
    "            #weirdness = value1 / value2\n",
    "            if value1 < value2:\n",
    "                weirdness1 = (-1) * (value1 / value2)\n",
    "            else:\n",
    "                weirdness1 =  value2 / value1\n",
    "            result = str(key1) +\";\" + str(weirdness1)+\"\\n\"\n",
    "            Write_file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weirdness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ураааа</td>\n",
       "      <td>0.065887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>объяснение</td>\n",
       "      <td>0.602400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>рэпчик</td>\n",
       "      <td>-0.474294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>начинаеться</td>\n",
       "      <td>-0.474294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>вкладывать</td>\n",
       "      <td>0.602400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ном</td>\n",
       "      <td>-0.711440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>учиться</td>\n",
       "      <td>-0.595807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>упругий</td>\n",
       "      <td>0.527100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>резина</td>\n",
       "      <td>0.527100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>вау</td>\n",
       "      <td>0.283823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>делочто</td>\n",
       "      <td>0.527100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>местный</td>\n",
       "      <td>0.718772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>рашер</td>\n",
       "      <td>-0.948587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>чтоз</td>\n",
       "      <td>0.527100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>тетрадить</td>\n",
       "      <td>0.527100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>вдвоём</td>\n",
       "      <td>0.766690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>отгадать</td>\n",
       "      <td>0.351400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>тотальный</td>\n",
       "      <td>-0.677562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ээ</td>\n",
       "      <td>0.702800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>дурка</td>\n",
       "      <td>0.210840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>часть</td>\n",
       "      <td>-0.889760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>обидка</td>\n",
       "      <td>-0.164972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>фэйсбук</td>\n",
       "      <td>0.527100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>слоу</td>\n",
       "      <td>0.087850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>заеать</td>\n",
       "      <td>0.421680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>свидание</td>\n",
       "      <td>0.702800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>умение</td>\n",
       "      <td>0.702800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>кант</td>\n",
       "      <td>-0.948587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>контекст</td>\n",
       "      <td>0.263550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>выиграть</td>\n",
       "      <td>0.342615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19283</th>\n",
       "      <td>торчать</td>\n",
       "      <td>-0.301823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19284</th>\n",
       "      <td>времениа</td>\n",
       "      <td>-0.474294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19285</th>\n",
       "      <td>сейч</td>\n",
       "      <td>0.702800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19286</th>\n",
       "      <td>солнце</td>\n",
       "      <td>0.815513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19287</th>\n",
       "      <td>лысый</td>\n",
       "      <td>0.602400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19288</th>\n",
       "      <td>меняй</td>\n",
       "      <td>-0.948587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19289</th>\n",
       "      <td>крепкий</td>\n",
       "      <td>0.687521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19290</th>\n",
       "      <td>жительство</td>\n",
       "      <td>-0.948587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19291</th>\n",
       "      <td>плоо</td>\n",
       "      <td>-0.278191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19292</th>\n",
       "      <td>откусить</td>\n",
       "      <td>-0.237147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19293</th>\n",
       "      <td>уда</td>\n",
       "      <td>0.843359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19294</th>\n",
       "      <td>пись</td>\n",
       "      <td>-0.316196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19295</th>\n",
       "      <td>оборваться</td>\n",
       "      <td>-0.474294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19296</th>\n",
       "      <td>бест</td>\n",
       "      <td>0.263550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19297</th>\n",
       "      <td>теплов</td>\n",
       "      <td>0.210840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19298</th>\n",
       "      <td>любиткогда</td>\n",
       "      <td>-0.948587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19299</th>\n",
       "      <td>англия</td>\n",
       "      <td>0.458348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19300</th>\n",
       "      <td>изложение</td>\n",
       "      <td>-0.948587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19301</th>\n",
       "      <td>воовать</td>\n",
       "      <td>-0.948587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19302</th>\n",
       "      <td>тожеа</td>\n",
       "      <td>-0.948587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19303</th>\n",
       "      <td>гречка</td>\n",
       "      <td>-0.542050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19304</th>\n",
       "      <td>прям</td>\n",
       "      <td>0.729830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19305</th>\n",
       "      <td>ебаать</td>\n",
       "      <td>-0.948587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19306</th>\n",
       "      <td>коко</td>\n",
       "      <td>-0.948587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19307</th>\n",
       "      <td>заражать</td>\n",
       "      <td>0.351400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19308</th>\n",
       "      <td>теплоить</td>\n",
       "      <td>0.527100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19309</th>\n",
       "      <td>выдерживать</td>\n",
       "      <td>-0.542050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19310</th>\n",
       "      <td>загорелый</td>\n",
       "      <td>-0.948587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19311</th>\n",
       "      <td>пожиратель</td>\n",
       "      <td>0.351400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19312</th>\n",
       "      <td>нэта</td>\n",
       "      <td>0.527100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19313 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  weirdness\n",
       "0           ураааа   0.065887\n",
       "1       объяснение   0.602400\n",
       "2           рэпчик  -0.474294\n",
       "3      начинаеться  -0.474294\n",
       "4       вкладывать   0.602400\n",
       "5              ном  -0.711440\n",
       "6          учиться  -0.595807\n",
       "7          упругий   0.527100\n",
       "8           резина   0.527100\n",
       "9              вау   0.283823\n",
       "10         делочто   0.527100\n",
       "11         местный   0.718772\n",
       "12           рашер  -0.948587\n",
       "13            чтоз   0.527100\n",
       "14       тетрадить   0.527100\n",
       "15          вдвоём   0.766690\n",
       "16        отгадать   0.351400\n",
       "17       тотальный  -0.677562\n",
       "18              ээ   0.702800\n",
       "19           дурка   0.210840\n",
       "20           часть  -0.889760\n",
       "21          обидка  -0.164972\n",
       "22         фэйсбук   0.527100\n",
       "23            слоу   0.087850\n",
       "24          заеать   0.421680\n",
       "25        свидание   0.702800\n",
       "26          умение   0.702800\n",
       "27            кант  -0.948587\n",
       "28        контекст   0.263550\n",
       "29        выиграть   0.342615\n",
       "...            ...        ...\n",
       "19283      торчать  -0.301823\n",
       "19284     времениа  -0.474294\n",
       "19285         сейч   0.702800\n",
       "19286       солнце   0.815513\n",
       "19287        лысый   0.602400\n",
       "19288        меняй  -0.948587\n",
       "19289      крепкий   0.687521\n",
       "19290   жительство  -0.948587\n",
       "19291         плоо  -0.278191\n",
       "19292     откусить  -0.237147\n",
       "19293          уда   0.843359\n",
       "19294         пись  -0.316196\n",
       "19295   оборваться  -0.474294\n",
       "19296         бест   0.263550\n",
       "19297       теплов   0.210840\n",
       "19298   любиткогда  -0.948587\n",
       "19299       англия   0.458348\n",
       "19300    изложение  -0.948587\n",
       "19301      воовать  -0.948587\n",
       "19302        тожеа  -0.948587\n",
       "19303       гречка  -0.542050\n",
       "19304         прям   0.729830\n",
       "19305       ебаать  -0.948587\n",
       "19306         коко  -0.948587\n",
       "19307     заражать   0.351400\n",
       "19308     теплоить   0.527100\n",
       "19309  выдерживать  -0.542050\n",
       "19310    загорелый  -0.948587\n",
       "19311   пожиратель   0.351400\n",
       "19312         нэта   0.527100\n",
       "\n",
       "[19313 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import codecs\n",
    "with codecs.open(\"dictionary.csv\", \"r\",\"utf-8\") as fin:\n",
    "    finy = pd.read_csv(fin,sep=';')\n",
    "    for row in finy:\n",
    "        row[0].encode('cp1251').decode('utf-8')\n",
    "    finy.to_csv('dict_to_kurs.csv',index = False)\n",
    "finy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificator(text,p_dict):\n",
    "    import csv\n",
    "    import codecs\n",
    "    import pymorphy2.tokenizers\n",
    "    import sklearn\n",
    "    \n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    \n",
    "    with codecs.open(text,\"r\",\"utf-8\") as text_t:\n",
    "        \n",
    "        text_t1 = csv.reader(text_t, delimiter = ';')\n",
    "\n",
    "        new_f = codecs.open(\"finish.csv\", \"w\",\"utf-8\")\n",
    "        new_f.write(\"text;W;class;class_right\\n\")\n",
    "\n",
    "        for row in text_t1:\n",
    "            W=0\n",
    "            txt_class = 0\n",
    "            words = pymorphy2.tokenizers.simple_word_tokenize(str(row[0]))\n",
    "            j = 0\n",
    "            finish = len(words)\n",
    "            while j < finish:\n",
    "                try:\n",
    "                    words[j] = morph.parse(words[j])[0].normal_form\n",
    "                    if len(words[j]) < 4:\n",
    "                        del words[j]\n",
    "                        finish = finish - 1\n",
    "                    else:\n",
    "                        with codecs.open(p_dict,\"r\",\"utf-8\") as p_dict1:\n",
    "                            dict1 = csv.reader(p_dict1, delimiter = ';')\n",
    "                            for row_dict in dict1:\n",
    "                                if words[j]==row_dict[0]:\n",
    "                                    W += float(row_dict[1])\n",
    "                    if W < -0.5:\n",
    "                        txt_class=-1\n",
    "                    if W > 0.5:\n",
    "                        txt_class=1\n",
    "                    if W>-0.5 and W<0.5:\n",
    "                        txt_class=0\n",
    "                    j = j + 1\n",
    "                except UnicodeDecodeError:\n",
    "                    del words[j]\n",
    "                    finish = finish - 1\n",
    "                except IndexError:\n",
    "                    del words[j]\n",
    "                    finish = finish - 1\n",
    "            result = str(row[0]) +\";\" + str(W) +\";\" + str(txt_class)+ \";\" + str(row[1]) +\"\\n\"\n",
    "            new_f.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-d3b97593aed5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#n_d_test = n_d.tail(int(n_count))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mclassificator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"positiv_test.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"dictionary.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mfin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"finish.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-4576673324fe>\u001b[0m in \u001b[0;36mclassificator\u001b[1;34m(text, p_dict)\u001b[0m\n\u001b[0;32m     29\u001b[0m                         \u001b[1;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mp_dict1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                             \u001b[0mdict1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_dict1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m';'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                             \u001b[1;32mfor\u001b[0m \u001b[0mrow_dict\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdict1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m                                 \u001b[1;32mif\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mrow_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                                     \u001b[0mW\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\codecs.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m         \u001b[1;34m\"\"\" Return the next decoded line from the input stream.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\codecs.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;34m\"\"\" Return the next decoded line from the input stream.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\codecs.py\u001b[0m in \u001b[0;36mreadline\u001b[1;34m(self, size, keepends)\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[1;31m# If size is given, we call read() only once\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreadsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirstline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m                 \u001b[1;31m# If we're at a \"\\r\" read one extra character (which might\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\codecs.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size, chars, firstline)\u001b[0m\n\u001b[0;32m    496\u001b[0m                 \u001b[0mnewdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m                 \u001b[0mnewdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m             \u001b[1;31m# decode bytes (those remaining from the last call included)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbytebuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnewdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "p_d_test = p_d.tail(int(p_count))\n",
    "#p_d_test = p_d.tail(100)\n",
    "p_d_test.to_csv('positiv_test.csv', sep =';', index = False, header = False)\n",
    "\n",
    "#n_d_test = n_d.tail(int(n_count))\n",
    "\n",
    "classificator(\"positiv_test.csv\",\"dictionary.csv\")\n",
    "\n",
    "fin = pd.read_csv(\"finish.csv\",sep=';')\n",
    "fin\n",
    "#total=pd.pivot_table(fin, aggfunc=sum,columns=\"class\",value=\"class_right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3717 3511 3067\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "with codecs.open(\"finish.csv\",\"r\",\"utf-8\") as text_t:\n",
    "    text_t1 = csv.reader(text_t, delimiter = ';')\n",
    "    N = 0\n",
    "    M = 0\n",
    "    L = 0\n",
    "    for row in text_t1:\n",
    "        if str(row[2]) == \"1\":\n",
    "            N = N + 1\n",
    "        if str(row[2]) == \"-1\":\n",
    "            M = M + 1\n",
    "        if str(row[2]) == \"0\":\n",
    "            L = L + 1\n",
    "    print(N,M,L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
